{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vQJzvMNiB2a"
      },
      "outputs": [],
      "source": [
        ""
      ],
      "id": "7vQJzvMNiB2a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xy3pqOaQcPDs",
        "outputId": "84bd875d-4e9c-470f-f913-4bdd419b1883"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [691 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,461 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,450 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,819 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,898 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [933 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,228 kB]\n",
            "Get:23 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.9 kB]\n",
            "Fetched 12.8 MB in 4s (3,520 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www.apache.org/dist/spark/ and enter as the spark version\n",
        "spark_version = \"spark-3.2.0\"\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "id": "Xy3pqOaQcPDs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJdY9JXFcVib"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Hashing\").getOrCreate()"
      ],
      "id": "DJdY9JXFcVib"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-g6P7gVy8l57"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, StopWordsRemover\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
      ],
      "id": "-g6P7gVy8l57"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epUukIYAq8pP",
        "outputId": "ca7f6ed2-98c0-4561-fe69-71fc1aa9bf64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "|review                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |sentiment|\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "|One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.|positive |\n",
            "|A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |positive |\n",
            "|I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |positive |\n",
            "|Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |negative |\n",
            "|Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. <br /><br />This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.<br /><br />The only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case with most of the people we encounter.<br /><br />The acting is good under Mr. Mattei's direction. Steve Buscemi, Rosario Dawson, Carol Kane, Michael Imperioli, Adrian Grenier, and the rest of the talented cast, make these characters come alive.<br /><br />We wish Mr. Mattei good luck and await anxiously for his next work.                                                                                                                                                                                                                                                                                                                                                                                                                                                            |positive |\n",
            "|Probably my all-time favorite movie, a story of selflessness, sacrifice and dedication to a noble cause, but it's not preachy or boring. It just never gets old, despite my having seen it some 15 or more times in the last 25 years. Paul Lukas' performance brings tears to my eyes, and Bette Davis, in one of her very few truly sympathetic roles, is a delight. The kids are, as grandma says, more like \"dressed-up midgets\" than children, but that only makes them more fun to watch. And the mother's slow awakening to what's happening in the world and under her own roof is believable and startling. If I had a dozen thumbs, they'd all be \"up\" for this movie.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |positive |\n",
            "|I sure would like to see a resurrection of a up dated Seahunt series with the tech they have today it would bring back the kid excitement in me.I grew up on black and white TV and Seahunt with Gunsmoke were my hero's every week.You have my vote for a comeback of a new sea hunt.We need a change of pace in TV and this would work for a world of under water adventure.Oh by the way thank you for an outlet like this to view many viewpoints about TV and the many movies.So any ole way I believe I've got what I wanna say.Would be nice to read some more plus points about sea hunt.If my rhymes would be 10 lines would you let me submit,or leave me out to be in doubt and have me to quit,If this is so then I must go so lets do it.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |positive |\n",
            "|This show was an amazing, fresh & innovative idea in the 70's when it first aired. The first 7 or 8 years were brilliant, but things dropped off after that. By 1990, the show was not really funny anymore, and it's continued its decline further to the complete waste of time it is today.<br /><br />It's truly disgraceful how far this show has fallen. The writing is painfully bad, the performances are almost as bad - if not for the mildly entertaining respite of the guest-hosts, this show probably wouldn't still be on the air. I find it so hard to believe that the same creator that hand-selected the original cast also chose the band of hacks that followed. How can one recognize such brilliance and then see fit to replace it with such mediocrity? I felt I must give 2 stars out of respect for the original cast that made this show such a huge success. As it is now, the show is just awful. I can't believe it's still on the air.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |negative |\n",
            "|Encouraged by the positive comments about this film on here I was looking forward to watching this film. Bad mistake. I've seen 950+ films and this is truly one of the worst of them - it's awful in almost every way: editing, pacing, storyline, 'acting,' soundtrack (the film's only song - a lame country tune - is played no less than four times). The film looks cheap and nasty and is boring in the extreme. Rarely have I been so happy to see the end credits of a film. <br /><br />The only thing that prevents me giving this a 1-score is Harvey Keitel - while this is far from his best performance he at least seems to be making a bit of an effort. One for Keitel obsessives only.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |negative |\n",
            "|If you like original gut wrenching laughter you will like this movie. If you are young or old then you will love this movie, hell even my mom liked it.<br /><br />Great Camp!!!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |positive |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Read in CSV\n",
        "from pyspark import SparkFiles\n",
        "df = spark.read.csv(SparkFiles.get(\"/content/IMDB Dataset.csv\"),sep=\",\", escape='\"', encoding=\"utf-8\", quote='\"',  header=True)\n",
        "\n",
        "# Show DataFrame\n",
        "df.show(10, truncate=False)"
      ],
      "id": "epUukIYAq8pP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AYjLGsfWvbQ",
        "outputId": "48b31ed5-b3aa-4184-f816-1f53d78c072e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimension of the Dataframe is: (50000, 2)\n",
            "Number of Rows are: 50000\n",
            "Number of Columns are: 2\n"
          ]
        }
      ],
      "source": [
        "# Check number of rows and columns \n",
        "row = df.count()\n",
        "col = len(df.columns)\n",
        "\n",
        "print(f'Dimension of the Dataframe is: {(row,col)}')\n",
        "print(f'Number of Rows are: {row}')\n",
        "print(f'Number of Columns are: {col}')"
      ],
      "id": "4AYjLGsfWvbQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aH5QlBE7jxs",
        "outputId": "6b26b4fd-13e8-4e93-ff65-7687700ea3d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+---------+--------------------+\n",
            "|              review|sentiment|               words|\n",
            "+--------------------+---------+--------------------+\n",
            "|One of the other ...| positive|[one, of, the, ot...|\n",
            "|A wonderful littl...| positive|[a, wonderful, li...|\n",
            "|I thought this wa...| positive|[i, thought, this...|\n",
            "|Basically there's...| negative|[basically, there...|\n",
            "|Petter Mattei's \"...| positive|[petter, mattei's...|\n",
            "|Probably my all-t...| positive|[probably, my, al...|\n",
            "|I sure would like...| positive|[i, sure, would, ...|\n",
            "|This show was an ...| negative|[this, show, was,...|\n",
            "|Encouraged by the...| negative|[encouraged, by, ...|\n",
            "|If you like origi...| positive|[if, you, like, o...|\n",
            "|Phil the Alien is...| negative|[phil, the, alien...|\n",
            "|I saw this movie ...| negative|[i, saw, this, mo...|\n",
            "|So im not a big f...| negative|[so, im, not, a, ...|\n",
            "|The cast played S...| negative|[the, cast, playe...|\n",
            "|This a fantastic ...| positive|[this, a, fantast...|\n",
            "|Kind of drawn in ...| negative|[kind, of, drawn,...|\n",
            "|Some films just s...| positive|[some, films, jus...|\n",
            "|This movie made i...| negative|[this, movie, mad...|\n",
            "|I remember this f...| positive|[i, remember, thi...|\n",
            "|An awful film! It...| negative|[an, awful, film!...|\n",
            "+--------------------+---------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Dimension of the Dataframe is: (50000, 3)\n",
            "Number of Rows are: 50000\n",
            "Number of Columns are: 3\n"
          ]
        }
      ],
      "source": [
        "# Tokenize DataFrame\n",
        "tokened = Tokenizer(inputCol=\"review\", outputCol=\"words\")\n",
        "tokened_transformed = tokened.transform(df)\n",
        "tokened_transformed.show()\n",
        "\n",
        "row = tokened_transformed.count()\n",
        "col = len(tokened_transformed.columns)\n",
        "\n",
        "print(f'Dimension of the Dataframe is: {(row,col)}')\n",
        "print(f'Number of Rows are: {row}')\n",
        "print(f'Number of Columns are: {col}')"
      ],
      "id": "-aH5QlBE7jxs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNatG6MY8zf3",
        "outputId": "869b03cc-8001-4b5c-d7e2-50693eef8998"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+---------+--------------------+--------------------+\n",
            "|              review|sentiment|               words|       Wordsfiltered|\n",
            "+--------------------+---------+--------------------+--------------------+\n",
            "|One of the other ...| positive|[one, of, the, ot...|[one, reviewers, ...|\n",
            "|A wonderful littl...| positive|[a, wonderful, li...|[wonderful, littl...|\n",
            "|I thought this wa...| positive|[i, thought, this...|[thought, wonderf...|\n",
            "|Basically there's...| negative|[basically, there...|[basically, famil...|\n",
            "|Petter Mattei's \"...| positive|[petter, mattei's...|[petter, mattei's...|\n",
            "|Probably my all-t...| positive|[probably, my, al...|[probably, all-ti...|\n",
            "|I sure would like...| positive|[i, sure, would, ...|[sure, like, see,...|\n",
            "|This show was an ...| negative|[this, show, was,...|[show, amazing,, ...|\n",
            "|Encouraged by the...| negative|[encouraged, by, ...|[encouraged, posi...|\n",
            "|If you like origi...| positive|[if, you, like, o...|[like, original, ...|\n",
            "|Phil the Alien is...| negative|[phil, the, alien...|[phil, alien, one...|\n",
            "|I saw this movie ...| negative|[i, saw, this, mo...|[saw, movie, 12, ...|\n",
            "|So im not a big f...| negative|[so, im, not, a, ...|[im, big, fan, bo...|\n",
            "|The cast played S...| negative|[the, cast, playe...|[cast, played, sh...|\n",
            "|This a fantastic ...| positive|[this, a, fantast...|[fantastic, movie...|\n",
            "|Kind of drawn in ...| negative|[kind, of, drawn,...|[kind, drawn, ero...|\n",
            "|Some films just s...| positive|[some, films, jus...|[films, simply, r...|\n",
            "|This movie made i...| negative|[this, movie, mad...|[movie, made, one...|\n",
            "|I remember this f...| positive|[i, remember, thi...|[remember, film,i...|\n",
            "|An awful film! It...| negative|[an, awful, film!...|[awful, film!, mu...|\n",
            "+--------------------+---------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Dimension of the Dataframe is: (50000, 4)\n",
            "Number of Rows are: 50000\n",
            "Number of Columns are: 4\n"
          ]
        }
      ],
      "source": [
        "# Remove stop words\n",
        "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"Wordsfiltered\")\n",
        "removed_frame = remover.transform(tokened_transformed)\n",
        "removed_frame.show()\n",
        "\n",
        "row = removed_frame.count()\n",
        "col = len(removed_frame.columns)\n",
        "\n",
        "print(f'Dimension of the Dataframe is: {(row,col)}')\n",
        "print(f'Number of Rows are: {row}')\n",
        "print(f'Number of Columns are: {col}')"
      ],
      "id": "tNatG6MY8zf3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXwjKUIa-pU-",
        "outputId": "a858f08b-c72c-46dd-9280-ff057b0256ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+---------+--------------------+--------------------+--------------------+\n",
            "|              review|sentiment|               words|       Wordsfiltered|        hashedValues|\n",
            "+--------------------+---------+--------------------+--------------------+--------------------+\n",
            "|One of the other ...| positive|[one, of, the, ot...|[one, reviewers, ...|(262144,[3280,436...|\n",
            "|A wonderful littl...| positive|[a, wonderful, li...|[wonderful, littl...|(262144,[120,521,...|\n",
            "|I thought this wa...| positive|[i, thought, this...|[thought, wonderf...|(262144,[1043,139...|\n",
            "|Basically there's...| negative|[basically, there...|[basically, famil...|(262144,[6512,853...|\n",
            "|Petter Mattei's \"...| positive|[petter, mattei's...|[petter, mattei's...|(262144,[2751,392...|\n",
            "|Probably my all-t...| positive|[probably, my, al...|[probably, all-ti...|(262144,[5381,158...|\n",
            "|I sure would like...| positive|[i, sure, would, ...|[sure, like, see,...|(262144,[1889,545...|\n",
            "|This show was an ...| negative|[this, show, was,...|[show, amazing,, ...|(262144,[2437,825...|\n",
            "|Encouraged by the...| negative|[encouraged, by, ...|[encouraged, posi...|(262144,[8538,149...|\n",
            "|If you like origi...| positive|[if, you, like, o...|[like, original, ...|(262144,[25629,31...|\n",
            "|Phil the Alien is...| negative|[phil, the, alien...|[phil, alien, one...|(262144,[1326,172...|\n",
            "|I saw this movie ...| negative|[i, saw, this, mo...|[saw, movie, 12, ...|(262144,[5451,702...|\n",
            "|So im not a big f...| negative|[so, im, not, a, ...|[im, big, fan, bo...|(262144,[3493,427...|\n",
            "|The cast played S...| negative|[the, cast, playe...|[cast, played, sh...|(262144,[5670,761...|\n",
            "|This a fantastic ...| positive|[this, a, fantast...|[fantastic, movie...|(262144,[6558,215...|\n",
            "|Kind of drawn in ...| negative|[kind, of, drawn,...|[kind, drawn, ero...|(262144,[2101,243...|\n",
            "|Some films just s...| positive|[some, films, jus...|[films, simply, r...|(262144,[2701,161...|\n",
            "|This movie made i...| negative|[this, movie, mad...|[movie, made, one...|(262144,[329,3535...|\n",
            "|I remember this f...| positive|[i, remember, thi...|[remember, film,i...|(262144,[1009,378...|\n",
            "|An awful film! It...| negative|[an, awful, film!...|[awful, film!, mu...|(262144,[3924,156...|\n",
            "+--------------------+---------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Dimension of the Dataframe is: (50000, 5)\n",
            "Number of Rows are: 50000\n",
            "Number of Columns are: 5\n"
          ]
        }
      ],
      "source": [
        "# Run the hashing term frequency\n",
        "hashing = HashingTF(inputCol=\"Wordsfiltered\", outputCol=\"hashedValues\")\n",
        "\n",
        "# Transform into a DF\n",
        "hashed_df = hashing.transform(removed_frame)\n",
        "hashed_df.show()\n",
        "\n",
        "row = hashed_df.count()\n",
        "col = len(hashed_df.columns)\n",
        "\n",
        "print(f'Dimension of the Dataframe is: {(row,col)}')\n",
        "print(f'Number of Rows are: {row}')\n",
        "print(f'Number of Columns are: {col}')"
      ],
      "id": "VXwjKUIa-pU-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYhWOMYGBCwF"
      },
      "outputs": [],
      "source": [
        "# Train test split\n",
        "training, testing = df.randomSplit([0.7, 0.3],1)"
      ],
      "id": "EYhWOMYGBCwF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDVqjD98JxX2",
        "outputId": "e4e87fd3-77ef-4782-bc97-665e96f19b40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Dataset Count: 50000\n",
            "Training Dataset Count: 35094\n",
            "Test Dataset Count: 14906\n"
          ]
        }
      ],
      "source": [
        "print(\"Training Dataset Count: \" + str(df.count()))\n",
        "print(\"Training Dataset Count: \" + str(training.count()))\n",
        "print(\"Test Dataset Count: \" + str(testing.count()))"
      ],
      "id": "nDVqjD98JxX2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VSYLOQ2wvls",
        "outputId": "b203dd93-4e94-4f86-becf-b2284a5a3586"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+---------+\n",
            "|              review|sentiment|\n",
            "+--------------------+---------+\n",
            "|\\b\\b\\b\\bA Turkish...| positive|\n",
            "|!!!! MILD SPOILER...| negative|\n",
            "|!!!! MILD SPOILER...| negative|\n",
            "|!!!! POSSIBLE MIL...| negative|\n",
            "|\" While sporadica...| negative|\n",
            "|\"... the beat is ...| positive|\n",
            "|\"2001: A Space Od...| positive|\n",
            "|\"200l: A Space Od...| positive|\n",
            "|\"8 SIMPLE RULES.....| positive|\n",
            "|\"9/11,\" hosted by...| positive|\n",
            "|\"A Cry in the Dar...| positive|\n",
            "|\"A Tale of Two Si...| positive|\n",
            "|\"A Thief in the N...| positive|\n",
            "|\"A bored televisi...| negative|\n",
            "|\"A death at a col...| negative|\n",
            "|\"A lot of the fil...| negative|\n",
            "|\"A research scien...| negative|\n",
            "|\"A total waste of...| negative|\n",
            "|\"A trio of treasu...| negative|\n",
            "|\"A truly nice sto...| positive|\n",
            "+--------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Show training data \n",
        "training.show()"
      ],
      "id": "8VSYLOQ2wvls"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiYDcE3bfWK9",
        "outputId": "1cdba76b-c29d-4e2e-aed9-3b3358cd3627"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('review', 'string'), ('sentiment', 'string')]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the data types\n",
        "training.dtypes\n"
      ],
      "id": "KiYDcE3bfWK9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REdixkXUEALT"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
      ],
      "id": "REdixkXUEALT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_k-b-HVvhogB",
        "outputId": "32e3a49c-1507-41c3-a6e1-81090e8e65d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------------------+------------------------------+------------------------------+------------------------------+-----+----------+\n",
            "|                        review|                 Wordsfiltered|                      features|                   probability|label|prediction|\n",
            "+------------------------------+------------------------------+------------------------------+------------------------------+-----+----------+\n",
            "|By now you've probably hear...|[by, now, you've, probably,...|(262144,[432,921,1189,2325,...|                     [1.0,0.0]|  0.0|       0.0|\n",
            "|In a style reminiscent of t...|[in, a, style, reminiscent,...|(262144,[303,437,666,861,18...|[0.9999999999999996,4.44089...|  0.0|       0.0|\n",
            "|Life is comprised of infini...|[life, is, comprised, of, i...|(262144,[303,2705,2977,3176...|[0.9999999999999951,4.88498...|  0.0|       0.0|\n",
            "|Universal Studios version o...|[universal, studios, versio...|(262144,[3924,3928,5942,596...|[0.9999999999999867,1.33226...|  0.0|       0.0|\n",
            "|**Attention Spoilers**<br /...|[**attention, spoilers**<br...|(262144,[350,810,1745,2488,...|[0.999999999999891,1.090239...|  0.0|       0.0|\n",
            "|It's easy to see why many p...|[it's, easy, to, see, why, ...|(262144,[169,1277,2624,2701...|[0.999999999999837,1.629807...|  0.0|       0.0|\n",
            "|Moving beyond words is this...|[moving, beyond, words, is,...|(262144,[3283,6512,9129,100...|[0.9999999999997773,2.22710...|  0.0|       0.0|\n",
            "|Four tales of terror regard...|[four, tales, of, terror, r...|(262144,[1891,2007,2701,356...|[0.9999999999997717,2.28261...|  0.0|       0.0|\n",
            "|There are some films that e...|[there, are, some, films, t...|(262144,[814,860,1745,2306,...|[0.999999999999621,3.790301...|  0.0|       0.0|\n",
            "|Trilogies are very interest...|[trilogies, are, very, inte...|(262144,[161,965,1643,2437,...|[0.9999999999995433,4.56745...|  0.0|       0.0|\n",
            "+------------------------------+------------------------------+------------------------------+------------------------------+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Logistic Regression F1 Score:  0.8605524070151653\n",
            "Logistic Regression Accuracy:  0.8605930497786126\n"
          ]
        }
      ],
      "source": [
        "# LOGISTIC REGRESSION MODEL \n",
        "\n",
        "# Create all the steps for the pipeline\n",
        "label_indexer = StringIndexer(inputCol='sentiment',outputCol='label')\n",
        "# code to change positive sentiment to 1 values - stringOrderType=\"frequencyAsc\"\n",
        "tokenizer = Tokenizer(inputCol=\"review\", outputCol=\"Wordsfiltered\")\n",
        "stopremove = StopWordsRemover(inputCol='Wordsfiltered',outputCol='hashedValues')\n",
        "hashingTF = HashingTF(inputCol=\"hashedValues\", outputCol='features')\n",
        "lr = LogisticRegression(maxIter=20, regParam=0.001)\n",
        "\n",
        "# Define pipeline\n",
        "pipeline = Pipeline(stages=[label_indexer, tokenizer, stopremove, hashingTF, lr])\n",
        "\n",
        "# Fit the pipeline to training reviews.\n",
        "lrmodel = pipeline.fit(training)\n",
        "\n",
        "# Tranform the model with the testing data\n",
        "predictions_lr = lrmodel.transform(testing)\n",
        "\n",
        "predictions_lr.filter(predictions_lr['label'] == 0) \\\n",
        "    .select(\"review\",\"Wordsfiltered\",\"features\",\"probability\",\"label\",\"prediction\") \\\n",
        "    .orderBy(\"probability\", ascending=False) \\\n",
        "    .show(n = 10, truncate = 30)\n",
        "\n",
        "# Evaluate Logistic Regression model\n",
        "f1_eval = MulticlassClassificationEvaluator(metricName='f1',predictionCol=\"prediction\")\n",
        "print(\"Logistic Regression F1 Score: \", f1_eval.evaluate(predictions_lr))\n",
        "accuracy_score = MulticlassClassificationEvaluator(metricName='accuracy',predictionCol=\"prediction\")\n",
        "print(\"Logistic Regression Accuracy: \", accuracy_score.evaluate(predictions_lr))"
      ],
      "id": "_k-b-HVvhogB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs2MOG-LSIYy",
        "outputId": "86ecefca-2c0e-4209-8588-e3048d0d4343"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------------------+------------------------------+------------------------------+------------------------------+-----+----------+\n",
            "|                        review|                 Wordsfiltered|                      features|                   probability|label|prediction|\n",
            "+------------------------------+------------------------------+------------------------------+------------------------------+-----+----------+\n",
            "|When people nowadays hear o...|[when, people, nowadays, he...|(262144,[1891,2306,3121,356...|[0.5923609418468325,0.40763...|  0.0|       0.0|\n",
            "|The best of the seven Sam F...|[the, best, of, the, seven,...|(262144,[2366,6034,7589,840...|[0.5885786355466045,0.41142...|  0.0|       0.0|\n",
            "|It's been a long time since...|[it's, been, a, long, time,...|(262144,[445,844,999,3048,4...|[0.5862893296639776,0.41371...|  0.0|       0.0|\n",
            "|Way back in 1955, the Briti...|[way, back, in, 1955,, the,...|(262144,[766,991,1889,2977,...|[0.58393075994923,0.4160692...|  0.0|       0.0|\n",
            "|This is arguably John Thaw'...|[this, is, arguably, john, ...|(262144,[4360,8297,8538,139...|[0.5834095826414111,0.41659...|  0.0|       0.0|\n",
            "|I watched this film for the...|[i, watched, this, film, fo...|(262144,[1689,3329,4319,612...|[0.5798349640996607,0.42016...|  0.0|       0.0|\n",
            "|Moving beyond words is this...|[moving, beyond, words, is,...|(262144,[3283,6512,9129,100...|[0.57891270590867,0.4210872...|  0.0|       0.0|\n",
            "|THE SHOP AROUND THE CORNER ...|[the, shop, around, the, co...|(262144,[619,1726,1857,2437...|[0.5783494532263012,0.42165...|  0.0|       0.0|\n",
            "|For Anthony Mann the Wester...|[for, anthony, mann, the, w...|(262144,[2724,4210,5670,596...|[0.577458614645421,0.422541...|  0.0|       0.0|\n",
            "|There are some films that e...|[there, are, some, films, t...|(262144,[814,860,1745,2306,...|[0.5766027034818823,0.42339...|  0.0|       0.0|\n",
            "+------------------------------+------------------------------+------------------------------+------------------------------+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Random Forest F1 Score:  0.6705239098370537\n",
            "Random Forest Accuracy:  0.67469475379042\n"
          ]
        }
      ],
      "source": [
        "### RANDOM FOREST MODEL \n",
        "\n",
        "# Create all the steps for the pipeline\n",
        "label_indexer = StringIndexer(inputCol='sentiment',outputCol='label')\n",
        "tokenizer = Tokenizer(inputCol=\"review\", outputCol=\"Wordsfiltered\")\n",
        "stopremove = StopWordsRemover(inputCol='Wordsfiltered',outputCol='hashedValues')\n",
        "hashingTF = HashingTF(inputCol=\"hashedValues\", outputCol='features')\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "# Define pipeline\n",
        "pipeline = Pipeline(stages=[label_indexer, tokenizer, stopremove, hashingTF, rf])\n",
        "\n",
        "# Fit the pipeline to training reviews.\n",
        "rfmodel = pipeline.fit(training)\n",
        "\n",
        "# Tranform the model with the testing data\n",
        "predictions_rf = rfmodel.transform(testing)\n",
        "\n",
        "predictions_rf.filter(predictions_rf['label'] == 0) \\\n",
        "    .select(\"review\",\"Wordsfiltered\",\"features\",\"probability\",\"label\",\"prediction\") \\\n",
        "    .orderBy(\"probability\", ascending=False) \\\n",
        "    .show(n = 10, truncate = 30)\n",
        "\n",
        "# Evaluate Random Forest model\n",
        "f1_eval = MulticlassClassificationEvaluator(metricName='f1',predictionCol=\"prediction\")\n",
        "print(\"Random Forest F1 Score: \", f1_eval.evaluate(predictions_rf))\n",
        "accuracy_score = MulticlassClassificationEvaluator(metricName='accuracy',predictionCol=\"prediction\")\n",
        "print(\"Random Forest Accuracy: \", accuracy_score.evaluate(predictions_rf))"
      ],
      "id": "Hs2MOG-LSIYy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9bh0rr-UbK5"
      },
      "outputs": [],
      "source": [
        "#Import naive\n",
        "from pyspark.ml.classification import NaiveBayes"
      ],
      "id": "H9bh0rr-UbK5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQtbDZccUKH7",
        "outputId": "68bff6c4-2c3c-4369-8d81-5952addd4bf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------------------+------------------------------+------------------------------+----------------------------+-----+----------+\n",
            "|                        review|                 Wordsfiltered|                      features|                 probability|label|prediction|\n",
            "+------------------------------+------------------------------+------------------------------+----------------------------+-----+----------+\n",
            "|Billy Hughes is a mute youn...|[billy, hughes, is, a, mute...|(262144,[1880,2705,4210,844...|[1.0,1.1001633128428086E-16]|  0.0|       0.0|\n",
            "|This small John Ford wester...|[this, small, john, ford, w...|(262144,[5381,6558,7433,762...|[1.0,1.1000321771336301E-16]|  0.0|       0.0|\n",
            "|Back in 2004 I saw \"True\", ...|[back, in, 2004, i, saw, \"t...|(262144,[2306,3785,4798,503...|[1.0,1.0910169090802258E-16]|  0.0|       0.0|\n",
            "|The third collaboration for...|[the, third, collaboration,...|(262144,[2626,4093,6501,840...|[1.0,1.0885433043067308E-16]|  0.0|       0.0|\n",
            "|Minor Spoilers<br /><br />I...|[minor, spoilers<br, /><br,...|(262144,[2480,5471,5670,592...| [1.0,1.065791792775683E-16]|  0.0|       0.0|\n",
            "|John Leguizamo's one man sh...|[john, leguizamo's, one, ma...|(262144,[991,3992,5150,5381...| [1.0,1.063262727668787E-16]|  0.0|       0.0|\n",
            "|Joseph L. Mankiewicz is not...|[joseph, l., mankiewicz, is...|(262144,[528,1148,1232,2306...|[1.0,1.0252450119288943E-16]|  0.0|       0.0|\n",
            "|Wagon Master is a very uniq...|[wagon, master, is, a, very...|(262144,[2574,5381,6558,984...|[1.0,1.0234328396575871E-16]|  0.0|       0.0|\n",
            "|It's sort of crazy, but I t...|[it's, sort, of, crazy,, bu...|(262144,[5429,5451,5670,585...|[1.0,1.0055625627437184E-16]|  0.0|       0.0|\n",
            "|This story of the troubles ...|[this, story, of, the, trou...|(262144,[4558,8287,8482,853...|[1.0,1.0029761784478637E-16]|  0.0|       0.0|\n",
            "+------------------------------+------------------------------+------------------------------+----------------------------+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Naive Bayes F1 Score:  0.8578198816384754\n",
            "Naive Bayes Accuracy:  0.857842479538441\n"
          ]
        }
      ],
      "source": [
        "### NAIVE BAYES MODEL\n",
        "\n",
        "# Create all the steps for the pipeline\n",
        "label_indexer = StringIndexer(inputCol='sentiment',outputCol='label')\n",
        "tokenizer = Tokenizer(inputCol=\"review\", outputCol=\"Wordsfiltered\")\n",
        "stopremove = StopWordsRemover(inputCol='Wordsfiltered',outputCol='hashedValues')\n",
        "hashingTF = HashingTF(inputCol=\"hashedValues\", outputCol='features')\n",
        "nb = NaiveBayes(smoothing=1)\n",
        "\n",
        "# Define pipeline\n",
        "pipeline = Pipeline(stages=[label_indexer, tokenizer, stopremove, hashingTF, nb])\n",
        "\n",
        "# Fit the pipeline to training reviews.\n",
        "nbmodel = pipeline.fit(training)\n",
        "\n",
        "# Tranform the model with the testing data\n",
        "predictions_nb = nbmodel.transform(testing)\n",
        "\n",
        "predictions_nb.filter(predictions_nb['label'] == 0) \\\n",
        "    .select(\"review\",\"Wordsfiltered\",\"features\",\"probability\",\"label\",\"prediction\") \\\n",
        "    .orderBy(\"probability\", ascending=False) \\\n",
        "    .show(n = 10, truncate = 30)\n",
        "\n",
        "# Evaluate Naive Bayes model\n",
        "f1_eval = MulticlassClassificationEvaluator(metricName='f1',predictionCol=\"prediction\")\n",
        "print(\"Naive Bayes F1 Score: \", f1_eval.evaluate(predictions_nb))\n",
        "accuracy_score = MulticlassClassificationEvaluator(metricName='accuracy',predictionCol=\"prediction\")\n",
        "print(\"Naive Bayes Accuracy: \", accuracy_score.evaluate(predictions_nb))"
      ],
      "id": "JQtbDZccUKH7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ui21o0JReV6F"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from pyspark.ml.classification import LinearSVC"
      ],
      "id": "Ui21o0JReV6F"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bslTNuNxeLxd",
        "outputId": "1b28ee0a-3e43-4a46-e487-35663b4a4107"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------------------+------------------------------+------------------------------+-----+----------+\n",
            "|                        review|                 Wordsfiltered|                      features|label|prediction|\n",
            "+------------------------------+------------------------------+------------------------------+-----+----------+\n",
            "|\" Now in India's sunny 'cli...|[\", now, in, india's, sunny...|(262144,[535,1765,2701,7625...|  0.0|       0.0|\n",
            "|\" S som i himmelen \" .. as...|[\", s, som, i, himmelen, \"...|(262144,[5150,8538,12716,15...|  0.0|       0.0|\n",
            "|\"A Guy Thing\" may not be a ...|[\"a, guy, thing\", may, not,...|(262144,[6690,10077,13020,1...|  0.0|       0.0|\n",
            "|\"A Minute to Pray, A Second...|[\"a, minute, to, pray,, a, ...|(262144,[2701,6699,7136,902...|  0.0|       0.0|\n",
            "|\"A Mouse in the House\" is a...|[\"a, mouse, in, the, house\"...|(262144,[9747,10172,16259,1...|  0.0|       0.0|\n",
            "|\"A Slight Case of Murder\" i...|[\"a, slight, case, of, murd...|(262144,[4757,5429,8538,151...|  0.0|       0.0|\n",
            "|\"Ah Ritchie's made another ...|[\"ah, ritchie's, made, anot...|(262144,[2437,11422,13222,1...|  0.0|       0.0|\n",
            "|\"Ahh...I didn't order no am...|[\"ahh...i, didn't, order, n...|(262144,[1619,8538,9129,100...|  0.0|       1.0|\n",
            "|\"All men are guilty,\" says ...|[\"all, men, are, guilty,\", ...|(262144,[654,1640,2701,4131...|  0.0|       0.0|\n",
            "|\"Anchors Aweigh\" is the pro...|[\"anchors, aweigh\", is, the...|(262144,[154,369,6261,6946,...|  0.0|       0.0|\n",
            "+------------------------------+------------------------------+------------------------------+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "SVM F1 Score:  0.8770820179924248\n",
            "SVM Accuracy:  0.8770964712196431\n"
          ]
        }
      ],
      "source": [
        "### SVM MODEL \n",
        "\n",
        "# Create all the steps for the pipeline\n",
        "label_indexer = StringIndexer(inputCol='sentiment',outputCol='label')\n",
        "tokenizer = Tokenizer(inputCol=\"review\", outputCol=\"Wordsfiltered\")\n",
        "stopremove = StopWordsRemover(inputCol='Wordsfiltered',outputCol='hashedValues')\n",
        "hashingTF = HashingTF(inputCol=\"hashedValues\", outputCol='features')\n",
        "lsvc = LinearSVC()\n",
        "\n",
        "# Define pipeline\n",
        "pipeline = Pipeline(stages=[label_indexer, tokenizer, stopremove, hashingTF, lsvc])\n",
        "\n",
        "# Fit the pipeline to training reviews.\n",
        "lsvcmodel = pipeline.fit(training)\n",
        "\n",
        "# Tranform the model with the testing data\n",
        "predictions_svm = lsvcmodel.transform(testing)\n",
        "\n",
        "predictions_svm.filter(predictions_svm['label'] == 0) \\\n",
        "    .select(\"review\",\"Wordsfiltered\",\"features\",\"label\",\"prediction\") \\\n",
        "    .show(n = 10, truncate = 30)\n",
        "\n",
        "# Evaluate Logistic Regression model\n",
        "f1_eval = MulticlassClassificationEvaluator(metricName='f1',predictionCol=\"prediction\")\n",
        "print(\"SVM F1 Score: \", f1_eval.evaluate(predictions_svm))\n",
        "accuracy_score = MulticlassClassificationEvaluator(metricName='accuracy',predictionCol=\"prediction\")\n",
        "print(\"SVM Accuracy: \", accuracy_score.evaluate(predictions_svm))"
      ],
      "id": "bslTNuNxeLxd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_D3aRmY5nkKf",
        "outputId": "96af27a5-f6e1-4aeb-eabf-4916cdba2718"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------------------+------------------------------+------------------------------+-----+----------+\n",
            "|                        review|                 Wordsfiltered|                      features|label|prediction|\n",
            "+------------------------------+------------------------------+------------------------------+-----+----------+\n",
            "|\" Now in India's sunny 'cli...|[\", now, in, india's, sunny...|(262144,[535,1765,2701,7625...|  0.0|       0.0|\n",
            "|\" S som i himmelen \" .. as...|[\", s, som, i, himmelen, \"...|(262144,[5150,8538,12716,15...|  0.0|       0.0|\n",
            "|\"A Guy Thing\" may not be a ...|[\"a, guy, thing\", may, not,...|(262144,[6690,10077,13020,1...|  0.0|       0.0|\n",
            "|\"A Minute to Pray, A Second...|[\"a, minute, to, pray,, a, ...|(262144,[2701,6699,7136,902...|  0.0|       0.0|\n",
            "|\"A Mouse in the House\" is a...|[\"a, mouse, in, the, house\"...|(262144,[9747,10172,16259,1...|  0.0|       0.0|\n",
            "|\"A Slight Case of Murder\" i...|[\"a, slight, case, of, murd...|(262144,[4757,5429,8538,151...|  0.0|       0.0|\n",
            "|\"Ah Ritchie's made another ...|[\"ah, ritchie's, made, anot...|(262144,[2437,11422,13222,1...|  0.0|       0.0|\n",
            "|\"Ahh...I didn't order no am...|[\"ahh...i, didn't, order, n...|(262144,[1619,8538,9129,100...|  0.0|       1.0|\n",
            "|\"All men are guilty,\" says ...|[\"all, men, are, guilty,\", ...|(262144,[654,1640,2701,4131...|  0.0|       0.0|\n",
            "|\"Anchors Aweigh\" is the pro...|[\"anchors, aweigh\", is, the...|(262144,[154,369,6261,6946,...|  0.0|       0.0|\n",
            "+------------------------------+------------------------------+------------------------------+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cross validation for SVM model\n",
        "from pyspark.ml.feature import HashingTF\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "# Define pipeline\n",
        "pipeline = Pipeline(stages=[label_indexer, tokenizer, stopremove, hashingTF, lsvc])\n",
        "\n",
        "cv = CrossValidator(estimator=pipeline,\n",
        "                    estimatorParamMaps=ParamGridBuilder().build(),\n",
        "                    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"),\n",
        "                    numFolds=5)\n",
        "model_svc = cv.fit(training)\n",
        "# Tranform the model with the testing data\n",
        "predictions = model_svc.transform(testing)\n",
        "predictions.filter(predictions['label'] == 0) \\\n",
        "    .select(\"review\",\"Wordsfiltered\",\"features\",\"label\",\"prediction\") \\\n",
        "    .show(n = 10, truncate = 30)\n"
      ],
      "id": "_D3aRmY5nkKf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aARdYLsMeh4Z",
        "outputId": "bb6f3d3e-0ac7-4512-95c8-13af3748296f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.8723427748328098]\n"
          ]
        }
      ],
      "source": [
        "# Computing metrics\n",
        "avgMetricsGrid_svc = model_svc.avgMetrics\n",
        "print (avgMetricsGrid_svc)"
      ],
      "id": "aARdYLsMeh4Z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MWwxm2ceek6-",
        "outputId": "fad23b4e-d3b8-4f91-a89e-75856997dcc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy for this grid  0.8723427748328098\n"
          ]
        }
      ],
      "source": [
        "# SVM accuracy\n",
        "modelAcc_svc = max(avgMetricsGrid_svc)\n",
        "print(\"accuracy for this grid \", modelAcc_svc)"
      ],
      "id": "MWwxm2ceek6-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uINBi3DoZZ2z",
        "outputId": "f535013a-12a9-425b-e2e1-871d40dbe176"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[review: string, sentiment: string, label: double, Wordsfiltered: array<string>, hashedValues: array<string>, features: vector, rawPrediction: vector, prediction: double]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Best model\n",
        "model1 = model_svc.bestModel\n",
        "model1.transform(testing)"
      ],
      "id": "uINBi3DoZZ2z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bjCFSojjeEnw",
        "outputId": "c0b12d8c-2e0b-4104-e7f5-4575496a7683"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------------------+------------------------------+------------------------------+-----+----------+\n",
            "|                        review|                 Wordsfiltered|                      features|label|prediction|\n",
            "+------------------------------+------------------------------+------------------------------+-----+----------+\n",
            "|\" Now in India's sunny 'cli...|[\", now, in, india's, sunny...|(262144,[535,1765,2701,7625...|  0.0|       0.0|\n",
            "|\" S som i himmelen \" .. as...|[\", s, som, i, himmelen, \"...|(262144,[5150,8538,12716,15...|  0.0|       0.0|\n",
            "|\"A Guy Thing\" may not be a ...|[\"a, guy, thing\", may, not,...|(262144,[6690,10077,13020,1...|  0.0|       0.0|\n",
            "|\"A Minute to Pray, A Second...|[\"a, minute, to, pray,, a, ...|(262144,[2701,6699,7136,902...|  0.0|       0.0|\n",
            "|\"A Mouse in the House\" is a...|[\"a, mouse, in, the, house\"...|(262144,[9747,10172,16259,1...|  0.0|       0.0|\n",
            "|\"A Slight Case of Murder\" i...|[\"a, slight, case, of, murd...|(262144,[4757,5429,8538,151...|  0.0|       0.0|\n",
            "|\"Ah Ritchie's made another ...|[\"ah, ritchie's, made, anot...|(262144,[2437,11422,13222,1...|  0.0|       0.0|\n",
            "|\"Ahh...I didn't order no am...|[\"ahh...i, didn't, order, n...|(262144,[1619,8538,9129,100...|  0.0|       1.0|\n",
            "|\"All men are guilty,\" says ...|[\"all, men, are, guilty,\", ...|(262144,[654,1640,2701,4131...|  0.0|       0.0|\n",
            "|\"Anchors Aweigh\" is the pro...|[\"anchors, aweigh\", is, the...|(262144,[154,369,6261,6946,...|  0.0|       0.0|\n",
            "+------------------------------+------------------------------+------------------------------+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Prediction for the best model\n",
        "predictions_best = model1.transform(testing)\n",
        "predictions_best.filter(predictions_best['label'] == 0) \\\n",
        "    .select(\"review\",\"Wordsfiltered\",\"features\",\"label\",\"prediction\") \\\n",
        "    .show(n = 10, truncate = 30)"
      ],
      "id": "bjCFSojjeEnw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c2aaFWQ4eojq",
        "outputId": "f6a48e87-5853-4574-9946-ab41de90489f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM best model Accuracy:  0.8770964712196431\n"
          ]
        }
      ],
      "source": [
        "# Print best model accuracy\n",
        "accuracy_score = MulticlassClassificationEvaluator(metricName='accuracy',predictionCol=\"prediction\")\n",
        "print(\"SVM best model Accuracy: \", accuracy_score.evaluate(predictions_best))"
      ],
      "id": "c2aaFWQ4eojq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CFEAHW_6NB2N",
        "outputId": "08ec2834-75ae-4e4c-9619-46c9f8224762"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------------------+------------------------------+------------------------------+-----+----------+\n",
            "|                        review|                 Wordsfiltered|                      features|label|prediction|\n",
            "+------------------------------+------------------------------+------------------------------+-----+----------+\n",
            "|\" Now in India's sunny 'cli...|[\", now, in, india's, sunny...|(262144,[535,1765,2701,7625...|  0.0|       0.0|\n",
            "|\" S som i himmelen \" .. as...|[\", s, som, i, himmelen, \"...|(262144,[5150,8538,12716,15...|  0.0|       0.0|\n",
            "|\"A Guy Thing\" may not be a ...|[\"a, guy, thing\", may, not,...|(262144,[6690,10077,13020,1...|  0.0|       0.0|\n",
            "|\"A Minute to Pray, A Second...|[\"a, minute, to, pray,, a, ...|(262144,[2701,6699,7136,902...|  0.0|       0.0|\n",
            "|\"A Mouse in the House\" is a...|[\"a, mouse, in, the, house\"...|(262144,[9747,10172,16259,1...|  0.0|       0.0|\n",
            "|\"A Slight Case of Murder\" i...|[\"a, slight, case, of, murd...|(262144,[4757,5429,8538,151...|  0.0|       0.0|\n",
            "|\"Ah Ritchie's made another ...|[\"ah, ritchie's, made, anot...|(262144,[2437,11422,13222,1...|  0.0|       0.0|\n",
            "|\"Ahh...I didn't order no am...|[\"ahh...i, didn't, order, n...|(262144,[1619,8538,9129,100...|  0.0|       1.0|\n",
            "|\"All men are guilty,\" says ...|[\"all, men, are, guilty,\", ...|(262144,[654,1640,2701,4131...|  0.0|       0.0|\n",
            "|\"Anchors Aweigh\" is the pro...|[\"anchors, aweigh\", is, the...|(262144,[154,369,6261,6946,...|  0.0|       0.0|\n",
            "+------------------------------+------------------------------+------------------------------+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cross validation for Logistic regression\n",
        "from pyspark.ml.feature import HashingTF\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "# Define pipeline\n",
        "pipeline = Pipeline(stages=[label_indexer, tokenizer, stopremove, hashingTF, lr])\n",
        "paramGrid = ParamGridBuilder().addGrid(lr.regParam, (0.01, 0.1))\\\n",
        "                              .addGrid(lr.tol, (1e-5, 1e-6))\\\n",
        "                              .build()\n",
        "cv = CrossValidator(estimator=pipeline,\n",
        "                    estimatorParamMaps=paramGrid,\n",
        "                    evaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\"),\n",
        "                    numFolds=5)\n",
        "model = cv.fit(training)\n",
        "# Tranform the model with the testing data\n",
        "predictions = model.transform(testing)\n",
        "predictions.filter(predictions['label'] == 0) \\\n",
        "    .select(\"review\",\"Wordsfiltered\",\"features\",\"label\",\"prediction\") \\\n",
        "    .show(n = 10, truncate = 30)\n",
        "\n"
      ],
      "id": "CFEAHW_6NB2N"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xTuw-DG7ZScG",
        "outputId": "3a2eef83-6ffc-43bc-9004-3f7b318af26d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy:  0.8683751509459278\n"
          ]
        }
      ],
      "source": [
        "# Evaluate Logistic Regression model\n",
        "accuracy_score = MulticlassClassificationEvaluator(metricName='accuracy',predictionCol=\"prediction\")\n",
        "print(\"Logistic Regression Accuracy: \", accuracy_score.evaluate(predictions))"
      ],
      "id": "xTuw-DG7ZScG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "A_h9U5ZjQKVV",
        "outputId": "6b2d0704-116d-4c96-c219-f1836261b331"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{Param(parent='LogisticRegression_3f72a14a176e', name='regParam', doc='regularization parameter (>= 0).'): 0.1, Param(parent='LogisticRegression_3f72a14a176e', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0).'): 1e-05}\n"
          ]
        }
      ],
      "source": [
        "#print best parameters for logistic regression\n",
        "import numpy as np\n",
        "\n",
        "print(model.getEstimatorParamMaps()[ np.argmax(model.avgMetrics) ])"
      ],
      "id": "A_h9U5ZjQKVV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "g-Df7MfzT_Oy",
        "outputId": "81c05f07-b728-436a-ba45-e2190cbbc133"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.8570387061541025, 0.8570387061541025, 0.8609394834152646, 0.8609394834152646]\n"
          ]
        }
      ],
      "source": [
        "# Computing metrics\n",
        "avgMetricsGrid = model.avgMetrics\n",
        "print (avgMetricsGrid)"
      ],
      "id": "g-Df7MfzT_Oy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4G2M3p7tUNVH",
        "outputId": "288826e1-592b-4e21-9d5a-19af6267bb5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy for this grid  0.8609394834152646\n"
          ]
        }
      ],
      "source": [
        "# Accuracy for Logistic regression after Cross validation \n",
        "modelAcc = max(avgMetricsGrid)\n",
        "print(\"accuracy for this grid \", modelAcc)"
      ],
      "id": "4G2M3p7tUNVH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zQ4Jnc02RKaw"
      },
      "outputs": [],
      "source": [
        "### DATA TRANSFORMATION - NEW REVIEWS FOR CLASSIFICATION #####"
      ],
      "id": "zQ4Jnc02RKaw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5Tv7w5uahxxW",
        "outputId": "7aca86d7-5064-4525-e51d-113bb4d33203"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (1.4.27)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "pip install sqlalchemy"
      ],
      "id": "5Tv7w5uahxxW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zkVIOmHciW1O",
        "outputId": "b838165c-5b97-4c42-999b-965f310668d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: psycopg2 in /usr/local/lib/python3.7/dist-packages (2.7.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install psycopg2"
      ],
      "id": "zkVIOmHciW1O"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CSHAxNGdhvin"
      },
      "outputs": [],
      "source": [
        ""
      ],
      "id": "CSHAxNGdhvin"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RhzRFpwhhfBX",
        "outputId": "70e42eaa-e751-45c5-b7b9-7d1bff24f322"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
            "  \"\"\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StructType(List(StructField(review,StringType,true),StructField(sentiment,StringType,true)))\n",
            "+---+--------------------+--------------------+--------------------+\n",
            "|ind|               title|                 url|              review|\n",
            "+---+--------------------+--------------------+--------------------+\n",
            "|  0|     The Survivalist|https://www.imdb....|It's day 592 of C...|\n",
            "|  1| The Addams Family 2|https://www.imdb....|Wednesday uses Un...|\n",
            "|  2|          Witch Hunt|https://www.imdb....|Martha (Elizabeth...|\n",
            "|  3|      American Night|https://www.imdb....|This film start w...|\n",
            "|  4|Space Jam: A New ...|https://www.imdb....|LeBron James work...|\n",
            "|  5|       Escape Room 2|https://www.imdb....|Zoey Davis (Taylo...|\n",
            "|  6|Six Minutes to Mi...|https://www.imdb....|In 1939, Thomas M...|\n",
            "|  7|           The Stand|https://www.imdb....|It's a nine part ...|\n",
            "|  8|             Clarice|https://www.imdb....|Overall this seri...|\n",
            "|  9|     Broken Diamonds|https://www.imdb....|Very well acted. ...|\n",
            "| 10|          The Nevers|https://www.imdb....|The Nevers is not...|\n",
            "| 11|         Fried Barry|https://www.imdb....|I am not even com...|\n",
            "| 12|Cleanin' Up the T...|https://www.imdb....|Greetings again f...|\n",
            "| 13|           Detention|https://www.imdb....|This never got go...|\n",
            "| 14|Aileen Wuornos: A...|https://www.imdb....|On death row, ser...|\n",
            "| 15|   Vengeance Is Mine|https://www.imdb....|I saw Vengeance I...|\n",
            "| 16|            Free Guy|https://www.imdb....|Guy (Ryan Reynold...|\n",
            "| 17|    The Green Knight|https://www.imdb....|One of the very w...|\n",
            "| 18|Roadrunner: A Fil...|https://www.imdb....|Greetings again f...|\n",
            "| 19|     Black Lightning|https://www.imdb....|Jefferson Pierce ...|\n",
            "+---+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import psycopg2\n",
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "engine = create_engine(\"postgresql://uhjsyonveadkbs:6032bfc65d7a3e652a22410287ef209734fe3d25644efcade80d0912bfc13d56@ec2-54-229-68-88.eu-west-1.compute.amazonaws.com:5432/ddd07kc11jnnd7\")\n",
        "\n",
        "#postgresql://postgres:postgres@localhost:5432/movie_review\n",
        "\n",
        "pdf = pd.read_sql('SELECT * FROM IMDB_REVIEWS', engine)\n",
        "\n",
        "# Convert Pandas dataframe to spark DataFrame\n",
        "df_dvd = spark.createDataFrame(pdf)\n",
        "print(df.schema)\n",
        "df_dvd.show()"
      ],
      "id": "RhzRFpwhhfBX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AFV4VDecRvpH"
      },
      "outputs": [],
      "source": [
        "# Read in CSV\n",
        "#from pyspark import SparkFiles\n",
        "#df_dvd = spark.read.csv(SparkFiles.get(\"/content/new_upcoming_dvd_reviews.csv\"),sep=\",\", escape='\"', encoding=\"utf-8\", quote='\"',  header=True)\n",
        "\n",
        "# Show DataFrame\n",
        "#df_dvd.show(10, truncate=False)"
      ],
      "id": "AFV4VDecRvpH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_wQplfq5cJHH",
        "outputId": "a5ce1946-3c42-493d-edd9-71abf97f134c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+-----------------------+------------------------------+------------------------------+----------+\n",
            "|ind|                  title|                           URL|                        review|prediction|\n",
            "+---+-----------------------+------------------------------+------------------------------+----------+\n",
            "|  0|        The Survivalist|https://www.imdb.com/title/...|It's day 592 of Covid-19 De...|       1.0|\n",
            "|  1|    The Addams Family 2|https://www.imdb.com/title/...|Wednesday uses Uncle Fester...|       0.0|\n",
            "|  2|             Witch Hunt|https://www.imdb.com/title/...|Martha (Elizabeth Mitchell)...|       1.0|\n",
            "|  3|         American Night|https://www.imdb.com/title/...|This film start with a man ...|       1.0|\n",
            "|  4|Space Jam: A New Legacy|https://www.imdb.com/title/...|LeBron James worked hard to...|       1.0|\n",
            "|  5|          Escape Room 2|https://www.imdb.com/title/...|Zoey Davis (Taylor Russell)...|       1.0|\n",
            "|  6|Six Minutes to Midnight|https://www.imdb.com/title/...|In 1939, Thomas Miller teac...|       0.0|\n",
            "|  7|              The Stand|https://www.imdb.com/title/...|It's a nine part TV adaptat...|       1.0|\n",
            "|  8|                Clarice|https://www.imdb.com/title/...|Overall this series is unde...|       1.0|\n",
            "|  9|        Broken Diamonds|https://www.imdb.com/title/...|Very well acted. Hardships ...|       0.0|\n",
            "+---+-----------------------+------------------------------+------------------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test= df_dvd\n",
        "predictions_ul = model1.transform(test)\n",
        "predictions_ul.select(\"ind\",\"title\",\"URL\",\"review\",\"prediction\") \\\n",
        "    .show(n = 10, truncate = 30)\n"
      ],
      "id": "_wQplfq5cJHH"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of IMDB_data_cleaning_.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}